#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸“ä¸šå»ºæ¨¡ç³»ç»Ÿ - åŒ…å«è¯¦ç»†çš„ç›®æ ‡å˜é‡å®šä¹‰ã€æ¨¡å‹åˆ†æå’Œè¯„ä¼°
"""

import pandas as pd
import numpy as np
import sqlite3
from pathlib import Path
import json
import logging
from datetime import datetime
from typing import List, Dict, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ å’Œç»Ÿè®¡
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score
from sklearn.feature_selection import SelectKBest, f_regression
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

class ProfessionalModelingSystem:
    """ä¸“ä¸šå»ºæ¨¡ç³»ç»Ÿ"""
    
    def __init__(self, factor_data_path: str = None):
        self.factor_data_path = factor_data_path or "professional_factors/professional_factors.csv"
        self.results_dir = Path("professional_results")
        self.results_dir.mkdir(exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # æ•°æ®å’Œæ¨¡å‹
        self.data = None
        self.features = None
        self.targets = {}  # å¤šä¸ªç›®æ ‡å˜é‡
        self.models = {}
        self.model_results = {}
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_file = self.results_dir / f"professional_modeling_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_factor_data(self):
        """åŠ è½½å› å­æ•°æ®"""
        try:
            self.logger.info("åŠ è½½å› å­æ•°æ®...")
            self.data = pd.read_csv(self.factor_data_path)
            self.data['datetime'] = pd.to_datetime(self.data['datetime'])
            
            self.logger.info(f"å› å­æ•°æ®åŠ è½½å®Œæˆ: {len(self.data)} æ¡è®°å½•, {len(self.data.columns)} åˆ—")
            return True
            
        except Exception as e:
            self.logger.error(f"å› å­æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def prepare_target_variables(self):
        """å‡†å¤‡å¤šä¸ªç›®æ ‡å˜é‡"""
        try:
            self.logger.info("å‡†å¤‡ç›®æ ‡å˜é‡...")
            
            # æŒ‰äº¤æ˜“å¯¹å’Œæ—¶é—´æ¡†æ¶åˆ†ç»„å¤„ç†
            processed_data = []
            
            for (symbol, timeframe), group in self.data.groupby(['symbol', 'timeframe']):
                group = group.reset_index(drop=True).copy()
                
                # 1. æœªæ¥æ”¶ç›Šç‡ï¼ˆä¸åŒæœŸæ•°ï¼‰
                for period in [1, 3, 5, 10]:
                    group[f'future_return_{period}'] = group['close'].pct_change(period).shift(-period)
                    group[f'future_log_return_{period}'] = (np.log(group['close']) - np.log(group['close'].shift(period))).shift(-period)
                
                # 2. æœªæ¥æ³¢åŠ¨ç‡
                for period in [5, 10, 20]:
                    future_vol = group['close'].pct_change().rolling(period).std().shift(-period)
                    group[f'future_volatility_{period}'] = future_vol * np.sqrt(252)  # å¹´åŒ–
                
                # 3. æœªæ¥æœ€å¤§å›æ’¤
                for period in [10, 20]:
                    def calc_future_drawdown(series, window):
                        result = []
                        for i in range(len(series)):
                            if i + window < len(series):
                                future_prices = series.iloc[i:i+window]
                                cumulative = (1 + future_prices.pct_change()).cumprod()
                                rolling_max = cumulative.expanding().max()
                                drawdown = (cumulative - rolling_max) / rolling_max
                                result.append(drawdown.min())
                            else:
                                result.append(np.nan)
                        return pd.Series(result, index=series.index)
                    
                    group[f'future_max_drawdown_{period}'] = calc_future_drawdown(group['close'], period)
                
                # 4. æœªæ¥å¤æ™®æ¯”ç‡
                for period in [20]:
                    def calc_future_sharpe(series, window):
                        result = []
                        for i in range(len(series)):
                            if i + window < len(series):
                                future_returns = series.iloc[i:i+window].pct_change().dropna()
                                if len(future_returns) > 1 and future_returns.std() > 0:
                                    sharpe = future_returns.mean() / future_returns.std() * np.sqrt(252)
                                    result.append(sharpe)
                                else:
                                    result.append(np.nan)
                            else:
                                result.append(np.nan)
                        return pd.Series(result, index=series.index)
                    
                    group[f'future_sharpe_{period}'] = calc_future_sharpe(group['close'], period)
                
                # 5. åˆ†ç±»ç›®æ ‡ï¼ˆæ¶¨è·Œæ–¹å‘ï¼‰
                for period in [1, 5]:
                    future_return = group['close'].pct_change(period).shift(-period)
                    group[f'future_direction_{period}'] = (future_return > 0).astype(int)
                    
                    # ä¸‰åˆ†ç±»ï¼šæ¶¨/å¹³/è·Œ
                    group[f'future_trend_{period}'] = pd.cut(
                        future_return, 
                        bins=[-np.inf, -0.01, 0.01, np.inf], 
                        labels=[0, 1, 2]  # 0:è·Œ, 1:å¹³, 2:æ¶¨
                    ).astype(float)
                
                processed_data.append(group)
            
            self.data = pd.concat(processed_data, ignore_index=True)
            
            # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
            feature_columns = [col for col in self.data.columns 
                             if col not in ['timestamp', 'datetime', 'symbol', 'timeframe', 
                                          'open', 'high', 'low', 'close', 'volume'] 
                             and not col.startswith('future_')]
            
            target_columns = [col for col in self.data.columns if col.startswith('future_')]
            
            self.features = self.data[feature_columns].copy()
            
            for target_col in target_columns:
                self.targets[target_col] = self.data[target_col].copy()
            
            self.logger.info(f"ç›®æ ‡å˜é‡å‡†å¤‡å®Œæˆ: {len(feature_columns)} ä¸ªç‰¹å¾, {len(target_columns)} ä¸ªç›®æ ‡å˜é‡")
            self.logger.info(f"ç›®æ ‡å˜é‡ç±»å‹: {list(self.targets.keys())}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"å‡†å¤‡ç›®æ ‡å˜é‡å¤±è´¥: {e}")
            return False
    
    def train_professional_models(self, target_name: str = 'future_return_1'):
        """è®­ç»ƒä¸“ä¸šæ¨¡å‹"""
        try:
            self.logger.info(f"è®­ç»ƒä¸“ä¸šæ¨¡å‹ - ç›®æ ‡å˜é‡: {target_name}")
            
            if target_name not in self.targets:
                self.logger.error(f"ç›®æ ‡å˜é‡ {target_name} ä¸å­˜åœ¨")
                return False
            
            # å‡†å¤‡æ•°æ®
            X = self.features
            y = self.targets[target_name]
            
            # ç§»é™¤ç¼ºå¤±å€¼
            valid_indices = ~(X.isnull().any(axis=1) | y.isnull())
            X_clean = X[valid_indices].copy()
            y_clean = y[valid_indices].copy()
            
            if len(X_clean) < 100:
                self.logger.error("æœ‰æ•ˆæ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ¨¡å‹è®­ç»ƒ")
                return False
            
            # å¡«å……å‰©ä½™ç¼ºå¤±å€¼
            X_clean = X_clean.fillna(X_clean.median())
            
            # ç‰¹å¾é€‰æ‹©
            selector = SelectKBest(score_func=f_regression, k=min(50, X_clean.shape[1]))
            X_selected = selector.fit_transform(X_clean, y_clean)
            selected_features = X_clean.columns[selector.get_support()].tolist()
            
            self.logger.info(f"ç‰¹å¾é€‰æ‹©å®Œæˆï¼Œé€‰æ‹©äº† {len(selected_features)} ä¸ªç‰¹å¾")
            
            # æ•°æ®æ ‡å‡†åŒ–
            scaler = RobustScaler()
            X_scaled = scaler.fit_transform(X_selected)
            
            # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
            tscv = TimeSeriesSplit(n_splits=5)
            
            # å®šä¹‰ä¸“ä¸šæ¨¡å‹
            models = {
                'Linear Regression': LinearRegression(),
                'Ridge Regression': Ridge(alpha=1.0),
                'Lasso Regression': Lasso(alpha=0.1),
                'Elastic Net': ElasticNet(alpha=0.1, l1_ratio=0.5),
                'Random Forest': RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42),
                'Extra Trees': ExtraTreesRegressor(n_estimators=200, max_depth=10, random_state=42),
                'Gradient Boosting': GradientBoostingRegressor(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42),
                'SVR': SVR(kernel='rbf', C=1.0, gamma='scale'),
                'MLP': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
            }
            
            model_results = {}
            
            # è®­ç»ƒå’Œè¯„ä¼°æ¯ä¸ªæ¨¡å‹
            for name, model in models.items():
                self.logger.info(f"è®­ç»ƒ {name} æ¨¡å‹...")
                
                cv_scores = {
                    'mse': [],
                    'mae': [],
                    'r2': [],
                    'explained_variance': []
                }
                
                predictions = []
                actuals = []
                
                # äº¤å‰éªŒè¯
                for fold, (train_idx, val_idx) in enumerate(tscv.split(X_scaled)):
                    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]
                    y_train, y_val = y_clean.iloc[train_idx], y_clean.iloc[val_idx]
                    
                    try:
                        # è®­ç»ƒæ¨¡å‹
                        model.fit(X_train, y_train)
                        
                        # é¢„æµ‹
                        y_pred = model.predict(X_val)
                        
                        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                        mse = mean_squared_error(y_val, y_pred)
                        mae = mean_absolute_error(y_val, y_pred)
                        r2 = r2_score(y_val, y_pred)
                        ev = explained_variance_score(y_val, y_pred)
                        
                        cv_scores['mse'].append(mse)
                        cv_scores['mae'].append(mae)
                        cv_scores['r2'].append(r2)
                        cv_scores['explained_variance'].append(ev)
                        
                        predictions.extend(y_pred)
                        actuals.extend(y_val)
                        
                    except Exception as e:
                        self.logger.warning(f"{name} ç¬¬{fold+1}æŠ˜è®­ç»ƒå¤±è´¥: {e}")
                        continue
                
                if cv_scores['mse']:
                    # è®¡ç®—å¹³å‡åˆ†æ•°
                    avg_scores = {
                        'mse': np.mean(cv_scores['mse']),
                        'mae': np.mean(cv_scores['mae']),
                        'r2': np.mean(cv_scores['r2']),
                        'explained_variance': np.mean(cv_scores['explained_variance']),
                        'rmse': np.sqrt(np.mean(cv_scores['mse'])),
                        'mse_std': np.std(cv_scores['mse']),
                        'r2_std': np.std(cv_scores['r2'])
                    }
                    
                    # åœ¨å…¨éƒ¨æ•°æ®ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹
                    try:
                        model.fit(X_scaled, y_clean)
                        
                        model_results[name] = {
                            'model': model,
                            'scaler': scaler,
                            'selector': selector,
                            'selected_features': selected_features,
                            'scores': avg_scores,
                            'predictions': predictions,
                            'actuals': actuals
                        }
                        
                        self.logger.info(f"{name} è®­ç»ƒå®Œæˆ - RÂ²: {avg_scores['r2']:.4f}Â±{avg_scores['r2_std']:.4f}, RMSE: {avg_scores['rmse']:.6f}")
                        
                    except Exception as e:
                        self.logger.warning(f"{name} æœ€ç»ˆè®­ç»ƒå¤±è´¥: {e}")
                        continue
                else:
                    self.logger.warning(f"{name} æ‰€æœ‰æŠ˜éƒ½è®­ç»ƒå¤±è´¥")
            
            self.models[target_name] = model_results
            
            self.logger.info(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼ŒæˆåŠŸè®­ç»ƒ {len(model_results)} ä¸ªæ¨¡å‹")
            return True
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def comprehensive_model_evaluation(self, target_name: str = 'future_return_1'):
        """ç»¼åˆæ¨¡å‹è¯„ä¼°"""
        try:
            self.logger.info(f"ç»¼åˆæ¨¡å‹è¯„ä¼° - {target_name}")
            
            if target_name not in self.models or not self.models[target_name]:
                self.logger.error(f"æ²¡æœ‰æ‰¾åˆ° {target_name} çš„è®­ç»ƒæ¨¡å‹")
                return None
            
            model_results = self.models[target_name]
            
            # åˆ›å»ºè¯„ä¼°ç»“æœDataFrame
            evaluation_data = []
            
            for name, result in model_results.items():
                scores = result['scores']
                evaluation_data.append({
                    'Model': name,
                    'RÂ²': scores['r2'],
                    'RÂ²_std': scores['r2_std'],
                    'MSE': scores['mse'],
                    'MSE_std': scores['mse_std'],
                    'MAE': scores['mae'],
                    'RMSE': scores['rmse'],
                    'Explained_Variance': scores['explained_variance']
                })
            
            evaluation_df = pd.DataFrame(evaluation_data)
            evaluation_df = evaluation_df.sort_values('RÂ²', ascending=False)
            
            # ä¿å­˜è¯„ä¼°ç»“æœ
            evaluation_df.to_csv(self.results_dir / f"model_evaluation_{target_name}.csv", index=False)
            
            # ç”Ÿæˆè¯¦ç»†çš„å¯è§†åŒ–åˆ†æ
            self._create_comprehensive_plots(target_name, evaluation_df, model_results)
            
            # æ¨¡å‹ç¨³å®šæ€§åˆ†æ
            stability_analysis = self._analyze_model_stability(model_results)
            
            # é¢„æµ‹èƒ½åŠ›åˆ†æ
            prediction_analysis = self._analyze_prediction_capability(model_results)
            
            # ç»¼åˆåˆ†æç»“æœ
            comprehensive_results = {
                'target_variable': target_name,
                'evaluation_summary': evaluation_df.to_dict('records'),
                'best_model': evaluation_df.iloc[0]['Model'],
                'best_model_metrics': {
                    'RÂ²': float(evaluation_df.iloc[0]['RÂ²']),
                    'RMSE': float(evaluation_df.iloc[0]['RMSE']),
                    'MAE': float(evaluation_df.iloc[0]['MAE'])
                },
                'stability_analysis': stability_analysis,
                'prediction_analysis': prediction_analysis,
                'analysis_time': datetime.now().isoformat()
            }
            
            # ä¿å­˜ç»¼åˆåˆ†æç»“æœ
            with open(self.results_dir / f"comprehensive_analysis_{target_name}.json", 'w', encoding='utf-8') as f:
                json.dump(comprehensive_results, f, ensure_ascii=False, indent=2)
            
            self.logger.info("ç»¼åˆæ¨¡å‹è¯„ä¼°å®Œæˆ")
            return comprehensive_results
            
        except Exception as e:
            self.logger.error(f"ç»¼åˆæ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
            return None
    
    def _create_comprehensive_plots(self, target_name: str, evaluation_df: pd.DataFrame, model_results: dict):
        """åˆ›å»ºç»¼åˆåˆ†æå›¾è¡¨"""
        try:
            # 1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾
            fig, axes = plt.subplots(2, 3, figsize=(20, 12))
            fig.suptitle(f'ğŸ“Š ä¸“ä¸šæ¨¡å‹åˆ†æ - {target_name}', fontsize=16, fontweight='bold')
            
            # RÂ²å¯¹æ¯”ï¼ˆå¸¦è¯¯å·®æ¡ï¼‰
            models = evaluation_df['Model']
            r2_scores = evaluation_df['RÂ²']
            r2_errors = evaluation_df['RÂ²_std']
            
            bars1 = axes[0, 0].bar(range(len(models)), r2_scores, yerr=r2_errors, capsize=5)
            axes[0, 0].set_title('RÂ² Score (Â±std)', fontweight='bold')
            axes[0, 0].set_xticks(range(len(models)))
            axes[0, 0].set_xticklabels(models, rotation=45, ha='right')
            axes[0, 0].grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (bar, score) in enumerate(zip(bars1, r2_scores)):
                axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(r2_errors)*0.1, 
                               f'{score:.4f}', ha='center', va='bottom', fontweight='bold')
            
            # RMSEå¯¹æ¯”
            rmse_scores = evaluation_df['RMSE']
            bars2 = axes[0, 1].bar(range(len(models)), rmse_scores)
            axes[0, 1].set_title('RMSE', fontweight='bold')
            axes[0, 1].set_xticks(range(len(models)))
            axes[0, 1].set_xticklabels(models, rotation=45, ha='right')
            axes[0, 1].grid(True, alpha=0.3)
            
            # MAEå¯¹æ¯”
            mae_scores = evaluation_df['MAE']
            bars3 = axes[0, 2].bar(range(len(models)), mae_scores)
            axes[0, 2].set_title('MAE', fontweight='bold')
            axes[0, 2].set_xticks(range(len(models)))
            axes[0, 2].set_xticklabels(models, rotation=45, ha='right')
            axes[0, 2].grid(True, alpha=0.3)
            
            # é¢„æµ‹vså®é™…æ•£ç‚¹å›¾ï¼ˆæœ€ä½³æ¨¡å‹ï¼‰
            best_model_name = evaluation_df.iloc[0]['Model']
            best_model_result = model_results[best_model_name]
            
            predictions = best_model_result['predictions']
            actuals = best_model_result['actuals']
            
            axes[1, 0].scatter(actuals, predictions, alpha=0.6, s=20)
            axes[1, 0].plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], 'r--', linewidth=2)
            axes[1, 0].set_xlabel('å®é™…å€¼')
            axes[1, 0].set_ylabel('é¢„æµ‹å€¼')
            axes[1, 0].set_title(f'é¢„æµ‹ç²¾åº¦ - {best_model_name}', fontweight='bold')
            axes[1, 0].grid(True, alpha=0.3)
            
            # æ®‹å·®åˆ†æ
            residuals = np.array(predictions) - np.array(actuals)
            axes[1, 1].scatter(predictions, residuals, alpha=0.6, s=20)
            axes[1, 1].axhline(y=0, color='r', linestyle='--')
            axes[1, 1].set_xlabel('é¢„æµ‹å€¼')
            axes[1, 1].set_ylabel('æ®‹å·®')
            axes[1, 1].set_title('æ®‹å·®åˆ†æ', fontweight='bold')
            axes[1, 1].grid(True, alpha=0.3)
            
            # æ®‹å·®åˆ†å¸ƒ
            axes[1, 2].hist(residuals, bins=30, alpha=0.7, density=True)
            axes[1, 2].axvline(x=0, color='r', linestyle='--')
            axes[1, 2].set_xlabel('æ®‹å·®')
            axes[1, 2].set_ylabel('å¯†åº¦')
            axes[1, 2].set_title('æ®‹å·®åˆ†å¸ƒ', fontweight='bold')
            axes[1, 2].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(self.results_dir / f'comprehensive_model_analysis_{target_name}.png', 
                       dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºç»¼åˆåˆ†æå›¾è¡¨å¤±è´¥: {e}")
    
    def _analyze_model_stability(self, model_results: dict) -> dict:
        """åˆ†ææ¨¡å‹ç¨³å®šæ€§"""
        stability_analysis = {}
        
        for name, result in model_results.items():
            scores = result['scores']
            stability_analysis[name] = {
                'r2_coefficient_of_variation': scores['r2_std'] / abs(scores['r2']) if scores['r2'] != 0 else np.inf,
                'mse_coefficient_of_variation': scores['mse_std'] / scores['mse'] if scores['mse'] != 0 else np.inf,
                'stability_score': 1 / (1 + scores['r2_std']) if scores['r2_std'] > 0 else 1.0
            }
        
        return stability_analysis
    
    def _analyze_prediction_capability(self, model_results: dict) -> dict:
        """åˆ†æé¢„æµ‹èƒ½åŠ›"""
        prediction_analysis = {}
        
        for name, result in model_results.items():
            predictions = np.array(result['predictions'])
            actuals = np.array(result['actuals'])
            
            # æ–¹å‘å‡†ç¡®ç‡
            pred_direction = np.sign(predictions)
            actual_direction = np.sign(actuals)
            direction_accuracy = np.mean(pred_direction == actual_direction)
            
            # é¢„æµ‹èŒƒå›´è¦†ç›–ç‡
            pred_range = np.max(predictions) - np.min(predictions)
            actual_range = np.max(actuals) - np.min(actuals)
            range_coverage = min(pred_range / actual_range, actual_range / pred_range) if actual_range != 0 else 0
            
            prediction_analysis[name] = {
                'direction_accuracy': float(direction_accuracy),
                'range_coverage': float(range_coverage),
                'prediction_variance': float(np.var(predictions)),
                'actual_variance': float(np.var(actuals))
            }
        
        return prediction_analysis
    
    def run_complete_modeling(self):
        """è¿è¡Œå®Œæ•´çš„ä¸“ä¸šå»ºæ¨¡æµç¨‹"""
        try:
            self.logger.info("ğŸš€ å¼€å§‹ä¸“ä¸šå»ºæ¨¡åˆ†æ...")
            
            # 1. åŠ è½½æ•°æ®
            if not self.load_factor_data():
                return False
            
            # 2. å‡†å¤‡ç›®æ ‡å˜é‡
            if not self.prepare_target_variables():
                return False
            
            # 3. å¯¹ä¸»è¦ç›®æ ‡å˜é‡è¿›è¡Œå»ºæ¨¡
            main_targets = ['future_return_1', 'future_return_5', 'future_volatility_10']
            
            for target in main_targets:
                if target in self.targets:
                    self.logger.info(f"å¼€å§‹å»ºæ¨¡: {target}")
                    
                    # è®­ç»ƒæ¨¡å‹
                    if self.train_professional_models(target):
                        # ç»¼åˆè¯„ä¼°
                        self.comprehensive_model_evaluation(target)
                    else:
                        self.logger.warning(f"{target} å»ºæ¨¡å¤±è´¥")
            
            # 4. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
            self._generate_modeling_summary()
            
            self.logger.info("ğŸ‰ ä¸“ä¸šå»ºæ¨¡åˆ†æå®Œæˆï¼")
            return True
            
        except Exception as e:
            self.logger.error(f"ä¸“ä¸šå»ºæ¨¡åˆ†æå¤±è´¥: {e}")
            return False
    
    def _generate_modeling_summary(self):
        """ç”Ÿæˆå»ºæ¨¡æ€»ç»“æŠ¥å‘Š"""
        try:
            summary = {
                "ä¸“ä¸šå»ºæ¨¡åˆ†ææ€»ç»“": {
                    "åˆ†ææ—¶é—´": datetime.now().isoformat(),
                    "ç›®æ ‡å˜é‡è¯´æ˜": {
                        "future_return_1": "æœªæ¥1æœŸæ”¶ç›Šç‡ï¼ˆä¸»è¦é¢„æµ‹ç›®æ ‡ï¼‰",
                        "future_return_5": "æœªæ¥5æœŸæ”¶ç›Šç‡ï¼ˆä¸­æœŸè¶‹åŠ¿ï¼‰",
                        "future_volatility_10": "æœªæ¥10æœŸæ³¢åŠ¨ç‡ï¼ˆé£é™©é¢„æµ‹ï¼‰",
                        "future_direction_1": "æœªæ¥1æœŸæ¶¨è·Œæ–¹å‘ï¼ˆåˆ†ç±»ç›®æ ‡ï¼‰",
                        "future_max_drawdown_10": "æœªæ¥10æœŸæœ€å¤§å›æ’¤ï¼ˆé£é™©æŒ‡æ ‡ï¼‰"
                    },
                    "æ¨¡å‹æ”¹è¿›": [
                        "ä½¿ç”¨RobustScalerè¿›è¡Œæ•°æ®æ ‡å‡†åŒ–ï¼Œå¯¹å¼‚å¸¸å€¼æ›´é²æ£’",
                        "é‡‡ç”¨TimeSeriesSplitè¿›è¡Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯",
                        "å¢åŠ äº†9ç§ä¸“ä¸šæœºå™¨å­¦ä¹ æ¨¡å‹",
                        "å¼•å…¥æ¨¡å‹ç¨³å®šæ€§åˆ†æ",
                        "æ·»åŠ é¢„æµ‹èƒ½åŠ›åˆ†æï¼ˆæ–¹å‘å‡†ç¡®ç‡ã€èŒƒå›´è¦†ç›–ç‡ï¼‰",
                        "ä½¿ç”¨SelectKBestè¿›è¡Œç‰¹å¾é€‰æ‹©",
                        "å¢åŠ æ®‹å·®åˆ†æå’Œåˆ†å¸ƒæ£€éªŒ"
                    ],
                    "è¯„ä¼°æŒ‡æ ‡": [
                        "RÂ²å†³å®šç³»æ•°ï¼ˆè§£é‡Šæ–¹å·®æ¯”ä¾‹ï¼‰",
                        "RMSEå‡æ–¹æ ¹è¯¯å·®ï¼ˆé¢„æµ‹ç²¾åº¦ï¼‰",
                        "MAEå¹³å‡ç»å¯¹è¯¯å·®ï¼ˆé²æ£’æ€§æŒ‡æ ‡ï¼‰",
                        "æ–¹å‘å‡†ç¡®ç‡ï¼ˆè¶‹åŠ¿é¢„æµ‹èƒ½åŠ›ï¼‰",
                        "æ¨¡å‹ç¨³å®šæ€§ç³»æ•°ï¼ˆè·¨æ—¶é—´ç¨³å®šæ€§ï¼‰"
                    ]
                }
            }
            
            with open(self.results_dir / "modeling_summary.json", 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            self.logger.info("å»ºæ¨¡æ€»ç»“æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå»ºæ¨¡æ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¸“ä¸šå»ºæ¨¡ç³»ç»Ÿ")
    print("=" * 60)
    
    # åˆ›å»ºä¸“ä¸šå»ºæ¨¡ç³»ç»Ÿ
    pms = ProfessionalModelingSystem()
    
    # è¿è¡Œå®Œæ•´å»ºæ¨¡
    success = pms.run_complete_modeling()
    
    if success:
        print("\nâœ… ä¸“ä¸šå»ºæ¨¡åˆ†ææˆåŠŸå®Œæˆï¼")
        print("ğŸ“Š ä¸»è¦æ”¹è¿›:")
        print("  â€¢ å¤šä¸ªç›®æ ‡å˜é‡ï¼ˆæ”¶ç›Šç‡ã€æ³¢åŠ¨ç‡ã€æ–¹å‘ã€å›æ’¤ï¼‰")
        print("  â€¢ 9ç§ä¸“ä¸šæœºå™¨å­¦ä¹ æ¨¡å‹")
        print("  â€¢ æ—¶é—´åºåˆ—äº¤å‰éªŒè¯")
        print("  â€¢ æ¨¡å‹ç¨³å®šæ€§åˆ†æ")
        print("  â€¢ é¢„æµ‹èƒ½åŠ›åˆ†æ")
        print("  â€¢ æ®‹å·®åˆ†æå’Œåˆ†å¸ƒæ£€éªŒ")
    else:
        print("\nâŒ ä¸“ä¸šå»ºæ¨¡åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

if __name__ == "__main__":
    main() 